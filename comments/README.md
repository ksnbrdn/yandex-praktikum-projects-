# Определение токсичности комментариев  
Было проведено исследование, чтобы обучить модель классифицировать комментарии на позитивные и негативные. Нам надо было построить модель со значением метрики F1 не меньше 0.75.    
На этапе предобработки данных мы привели записи в столбце 'text' к нижнему регистру и подготовили их для дальнейшего обучения моделей.    
На этапе обучения мы разбили данные на тренировочную и тестовую выборки. Разбили данные на признаки и целевой признак, сохранили в отдельных переменных. 
Чтобы увеличить качество моделей при дисбалансе классов, применили технику upsampling к обучающей выборке.
Перевели тексты в векторный формат. Мы выбрали для обучения моделей метод мешка слов.   
Для обучения моделей мы применили следующие библиотеки: LogisticRegression, RandomForestClassifier, LightGBMClassifier и CatBoostClassifier.  
Для каждой модели мы подбирали оптимальные гиперпараметры с целью получения максимальной метрики F1. Наилучшей моделью стала LogisticRegression с максимальным значением метрики F1 на тренировочной выборке - 0.941.  
Мы проверили результаты лучшей модели LogisticRegression на тестовой выборке.   
По итогам анализа результатов было принято решение рекомендовать заказчику модель LogisticRegression с максимальным значением метрики F1 на тестовой выборке - 0.77.  

## Использованы библиотеки и методы:  
- pandas
- numpy
- matplotlib.pyplot
- re
- nltk
- wordnet
- sklearn
- catboost
- lightgbm
- tqdm
