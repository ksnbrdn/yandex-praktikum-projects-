# Прогнозирование оттока клиентов Банка  
Было проведено исследование, чтобы спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам надо было построить модель с предельно большим значением F1-меры.  
В нашем распоряжении данные о поведении клиентов и расторжении договоров с банком.   
В ходе работы была выполнена предобработка данных.  
Привели названия столбцов к нижнему регистру. Заполним пропуски в столбце 'tenure' медианным значением. Признаки 'rownumber' - индекс строки датафрейма, 'customerid' и 'surname' - идентификаторы клиента - не несут ценности для обучения будущей модели, поэтому мы их удалили.    
В столбцах 'gender' и 'geography' преобразовали категориальные признаки в численные с помощью техники прямого кодирования OHE. Это позволило нам работать со всеми моделями. Столбец 'geography' содержал 3 класса, 'gender'- 2 класса. В результате мы получили только 2 и 1 столбцов соответственно, что позволяет избежать дами-ловушки.    
Спрятанной тестовой выборки нет. Данные разбили на три части: обучающую, валидационную и тестовую в пропорции 60:20:20.    
Чтобы алгоритмам было легче обучать модели, привели признаки к одному масштабу с помощью метода стандартизации данных StandardScaler. В результате мы получили масштабированные признаки для трех выборок. Масштаб у всех признаков стал одинаковый.    
В наших данных имелся дисбаланс 1:4. Доля отрицательных ответов около 80% , положитительных - чуть больше 20%.  
Были исследованы модели Decision Tree Classifier, RandomForestClassifier и Logistic Regression без учета дисбаланса данных. На несбалансированных выборках лучшие результаты у RandomForestClassifier - мера F1 = 0.56. Самое высокое значение AUC-ROC у наилучшей модели дерева решений - 0.5.  
Чтобы увеличить качество модели при дисбалансе классов, применили техники: взвешивание классов, upsampling и downsampling. Применив технику downsampling, данных стало сильно мало, это могло привести к переобучению. Поэтому стали применять технику upsampling для дальнейшей проверки моделей.  
Исследовали class_weight='balanced' как отдельную методику борьбы с дисбалансом и проверили на каждой модели. Техника upsampling и методика class_weight='balanced' дали на выходе одинаковые показатели меры F1 лучших моделей. Мера F1 всех моделей стала больше.  
Были исследованы модели Decision Tree Classifier, RandomForestClassifier и Logistic Regression с учетом дисбаланса данных. Самое высокое значение AUC-ROC у наилучшей модели Logistic Regression - 0.5. Самый лучший показатель F1 у RandomForestClassifier - 0.61, с лучшим значением n_estimators = 21 и лучшим значением max_depth = 10. Выбрали эту модель для финального тестирования.  
На тестовой выборке F1 у лучшей модели RandomForestClassifier - 0.63.  
Построили ROC-кривую для лучшей модели RandomForestClassifier и изобразили её на графике. Также посчитали значение AUC-ROC наилучшей модели RandomForestClassifier: 0.845.  
Проверили нашу модель на адекватность, используя модель DummyClassifier. F1 модели DummyClassifier ниже, чем у нашей лучшей модели RandomForestClassifier. Наша модель адекватна и эффективна.    

## Использованы библиотеки и методы:    
- pandas
- numpy
- matplotlib.pyplot
- re
- sklearn
- tqdm

